{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN62tygRyfnmfv36EGE1i5q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/22491A4481/case122491A4481/blob/main/Untitled12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "LXXmoSxPCtPC",
        "outputId": "85a3f841-e0a7-4247-f06f-4fd73e843706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidParameterError",
          "evalue": "The 'container_path' parameter of load_files must be an instance of 'str' or an instance of 'os.PathLike'. Got                                                 review sentiment\n0    This movie was fantastic! The plot was engagin...  positive\n1    I didn't enjoy this movie. The storyline was p...  negative\n2    The actors did a great job, and I loved the ci...  positive\n3    The film was a waste of time. I wouldn’t recom...  negative\n4    An amazing film with a moving story and incred...  positive\n..                                                 ...       ...\n195  It was hard to sit through this movie; the pac...  negative\n196  The special effects were stunning, but the sto...  negative\n197  A beautifully crafted movie with a heartwarmin...  positive\n198   I fell asleep halfway through; it was that dull.  negative\n199    A true masterpiece, it deserves all the praise!  positive\n\n[200 rows x 2 columns] instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-eb7a2dc3cba3>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Assuming the dataset is available locally in 'aclImdb' folder structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/IMDB_200_reviews_sample.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Step 3: Preprocess the text data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_ignore\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             validate_parameter_constraints(\n\u001b[0m\u001b[1;32m    204\u001b[0m                 \u001b[0mparameter_constraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 )\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             raise InvalidParameterError(\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0;34mf\"The {param_name!r} parameter of {caller_name} must be\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;34mf\" {constraints_str}. Got {param_val!r} instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidParameterError\u001b[0m: The 'container_path' parameter of load_files must be an instance of 'str' or an instance of 'os.PathLike'. Got                                                 review sentiment\n0    This movie was fantastic! The plot was engagin...  positive\n1    I didn't enjoy this movie. The storyline was p...  negative\n2    The actors did a great job, and I loved the ci...  positive\n3    The film was a waste of time. I wouldn’t recom...  negative\n4    An amazing film with a moving story and incred...  positive\n..                                                 ...       ...\n195  It was hard to sit through this movie; the pac...  negative\n196  The special effects were stunning, but the sto...  negative\n197  A beautifully crafted movie with a heartwarmin...  positive\n198   I fell asleep halfway through; it was that dull.  negative\n199    A true masterpiece, it deserves all the praise!  positive\n\n[200 rows x 2 columns] instead."
          ]
        }
      ],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.datasets import load_files\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Step 2: Load the IMDB dataset\n",
        "# We use sklearn's 'load_files' to load the dataset\n",
        "# Assuming the dataset is available locally in 'aclImdb' folder structure\n",
        "data=pd.read_csv('/content/IMDB_200_reviews_sample.csv')\n",
        "dataset = load_files(data, categories=['pos', 'neg'], shuffle=True, random_state=42)\n",
        "\n",
        "# Step 3: Preprocess the text data\n",
        "X = dataset.data  # Movie reviews (text)\n",
        "y = dataset.target  # Sentiment labels (0=negative, 1=positive)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Convert the text data to numerical features using TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), max_features=5000)\n",
        "\n",
        "# Fit the vectorizer on the training data and transform both the training and test data\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 5: Train the Logistic Regression model\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Step 6: Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Step 7: Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Optional: Show some example predictions\n",
        "sample_reviews = [\n",
        "    \"This movie was fantastic! I loved the story and the performances.\",\n",
        "    \"Horrible film. Waste of time. I will never watch it again.\"\n",
        "]\n",
        "sample_tfidf = vectorizer.transform(sample_reviews)\n",
        "sample_predictions = classifier.predict(sample_tfidf)\n",
        "\n",
        "print(\"\\nSample Predictions:\")\n",
        "for review, prediction in zip(sample_reviews, sample_predictions):\n",
        "    sentiment = 'Positive' if prediction == 1 else 'Negative'\n",
        "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the data (assuming you have a CSV file)\n",
        "data = pd.read_csv(\"/content/IMDB_200_reviews_sample.csv\")  # Modify this path if your CSV file is elsewhere\n",
        "\n",
        "# Check the data structure\n",
        "print(data.head())\n",
        "\n",
        "# Step 3: Preprocess the text data\n",
        "X = data['review']  # Movie reviews (text)\n",
        "y = data['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)  # Convert sentiment to 0 (negative) and 1 (positive)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Convert the text data to numerical features using TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), max_features=5000)\n",
        "\n",
        "# Fit the vectorizer on the training data and transform both the training and test data\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 5: Train the Logistic Regression model\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Step 6: Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Step 7: Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Optional: Show some example predictions\n",
        "sample_reviews = [\n",
        "    \"This movie was fantastic! I loved the story and the performances.\",\n",
        "    \"Horrible film. Waste of time. I will never watch it again.\"\n",
        "]\n",
        "sample_tfidf = vectorizer.transform(sample_reviews)\n",
        "sample_predictions = classifier.predict(sample_tfidf)\n",
        "\n",
        "print(\"\\nSample Predictions:\")\n",
        "for review, prediction in zip(sample_reviews, sample_predictions):\n",
        "    sentiment = 'Positive' if prediction == 1 else 'Negative'\n",
        "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IK1WHx9FgIR",
        "outputId": "a2332914-08bf-490b-ee2e-b7c31a1fab34"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  This movie was fantastic! The plot was engagin...  positive\n",
            "1  I didn't enjoy this movie. The storyline was p...  negative\n",
            "2  The actors did a great job, and I loved the ci...  positive\n",
            "3  The film was a waste of time. I wouldn’t recom...  negative\n",
            "4  An amazing film with a moving story and incred...  positive\n",
            "Accuracy: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        22\n",
            "           1       1.00      1.00      1.00        18\n",
            "\n",
            "    accuracy                           1.00        40\n",
            "   macro avg       1.00      1.00      1.00        40\n",
            "weighted avg       1.00      1.00      1.00        40\n",
            "\n",
            "\n",
            "Sample Predictions:\n",
            "Review: This movie was fantastic! I loved the story and the performances.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Horrible film. Waste of time. I will never watch it again.\n",
            "Sentiment: Negative\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}